{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "「LSTM_Banana_Prediction_s1.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgVZL1KU5IVK"
      },
      "source": [
        "# 版本介紹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7pjLObL5SOd"
      },
      "source": [
        "香蕉價格預測版本s1，\n",
        "此版本目的是可以跑完模型並畫出圖，尚無判斷參數的選擇，以及預測結果是否合理\n",
        "重要資訊簡介:\n",
        "1. 氣候資料為365日 vs 1天價格\n",
        "2. 進行shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-IAZIwn0aV"
      },
      "source": [
        "# 原始氣候資料清洗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waczF5VBtaH1"
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import datetime\n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "834O6MchZrU3"
      },
      "source": [
        "# 檔案下載url\n",
        "weather_data_url = 'https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/amoswu/dataset/reportdaily_mean_fillna.csv'\n",
        "typhoon_data_url = 'https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/amoswu/dataset/TyphoonDatabase.csv'\n",
        "price_data_url = 'https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/lynnbai/dataset/Banana.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjAzVzu5ZtCD"
      },
      "source": [
        "# 將檔案下載至colab\n",
        "if not os.path.exists('weather.csv'): urllib.request.urlretrieve(weather_data_url, 'weather.csv') \n",
        "if not os.path.exists('typhoon.csv'): urllib.request.urlretrieve(typhoon_data_url, 'typhoon.csv') \n",
        "if not os.path.exists('price.csv'): urllib.request.urlretrieve(price_data_url, 'price.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oln1gir-mo4m"
      },
      "source": [
        "# 所有城市對照英文代碼\n",
        "city = {\n",
        "    '基隆市':'KLU',\n",
        "    '臺北市':'TPE',\n",
        "    '新北市':'TPH',\n",
        "    '桃園市':'TYC',\n",
        "    '新竹市':'HSC',\n",
        "    '新竹縣':'HSH',\n",
        "    '苗栗縣':'MAL',\n",
        "    '臺中市':'TXG',\n",
        "    '彰化縣':'CWH',\n",
        "    '南投縣':'NTO',\n",
        "    '雲林縣':'YLH',\n",
        "    '嘉義市':'CYI',\n",
        "    '嘉義縣':'CHY',\n",
        "    '臺南市':'TNN',\n",
        "    '高雄市':'KHH',\n",
        "    '屏東縣':'IUH',\n",
        "    '宜蘭縣':'ILN',\n",
        "    '花蓮縣':'HWA',\n",
        "    '臺東縣':'TTT'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfKfQo5mmtE4"
      },
      "source": [
        "df = pd.read_csv('weather.csv', encoding='utf-8')\n",
        "# print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnbsB7J3muaU"
      },
      "source": [
        "# 使用index做merge\n",
        "df_date = df['date'].drop_duplicates().to_frame().set_index('date')\n",
        "\n",
        "for cityname, citycode in city.items():\n",
        "    df_city = df.loc[df['city'] == cityname].add_suffix('_' + citycode).set_index('date' + '_' + citycode)\n",
        "    df_date = pd.merge(df_date, df_city, how='left', left_index = True, right_index = True)\n",
        "\n",
        "df_date.to_csv('all.csv', encoding='utf-8')\n",
        "# print(pd.read_csv('all.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB524fY8muiE",
        "outputId": "217e909a-f5f1-4cd7-a0ba-b0c2858c0c4f"
      },
      "source": [
        "typhoon_df = pd.read_csv('typhoon.csv', encoding='utf-8')\n",
        "weather_df = pd.read_csv('all.csv', encoding='utf-8')\n",
        "weather_df['WarnMark'] = 0\n",
        "# print(weather_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (130,132,305,307) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAfAZC2knE4S"
      },
      "source": [
        "颱風警報期間控制：period_ctrl 可調整 weather_df 資料表 WarnMark 欄位值為 1 之天數，如下範例：\n",
        "* period_ctrl = 0, 2020-06-03 ... 1, 2020-06-04 ... 1\n",
        "* period_ctrl = 2, 2020-06-01 ... 1, 2020-06-02 ... 1, 2020-06-03 ... 1, 2020-06-04 ... 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bv93q6BnAD7"
      },
      "source": [
        "# 警報日期處理\n",
        "import datetime\n",
        "\n",
        "period_ctrl = 0 # 颱風警報期間控制\n",
        "warn_mark = list()\n",
        "warn_start = list()\n",
        "warn_end = list()\n",
        "\n",
        "for wd in typhoon_df['Warning']:\n",
        "  start = datetime.datetime.strptime(wd[0:10], '%Y-%m-%d')\n",
        "  end = datetime.datetime.strptime(wd[17:27], '%Y-%m-%d')\n",
        "  period = end - start # 每次颱風之期間時間資訊 (若為一天內的暫寫入0，表示僅有當天)\n",
        "  # print(period.days)\n",
        "  \n",
        "  ctrl_start = start\n",
        "  i = 0\n",
        "  \n",
        "  warn_mark.append(wd[0:10])\n",
        "  while i < period.days: # 利用颱風天數期間append期間日期進warn_mark列表\n",
        "    start = start + datetime.timedelta(days=1)\n",
        "    warn_mark.append(datetime.datetime.strftime(start, '%Y-%m-%d'))\n",
        "    i = i + 1\n",
        "  warn_mark.append(wd[17:27])\n",
        "\n",
        "  if period_ctrl != 0:\n",
        "    j = 0\n",
        "    while j < period_ctrl:\n",
        "      ctrl_start = ctrl_start - datetime.timedelta(days=1)\n",
        "      warn_mark.append(datetime.datetime.strftime(ctrl_start, '%Y-%m-%d'))\n",
        "      j = j + 1\n",
        "\n",
        "unique_set = set(warn_mark) # 打散日期排序\n",
        "unique_list = list(unique_set)\n",
        "warn_mark = list()\n",
        "warn_mark = unique_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUyTyfQbnAGp"
      },
      "source": [
        "# 氣候欄位List\n",
        "dataset_column_lists = ['date','city_KLU','StnPres_KLU','SeaPres_KLU','StnPresMax_KLU','StnPresMaxTime_KLU','StnPresMin_KLU','StnPresMinTime_KLU','Temperature_KLU','TMax_KLU','TMaxTime_KLU','TMin_KLU','TMinTime_KLU','TdDewPoint_KLU','RH_KLU','RHMin_KLU','RHMinTime_KLU','WS_KLU','WD_KLU','WSGust_KLU','WDGust_KLU','WGustTime_KLU','Precp_KLU','PrecpHour_KLU','PrecpMax10_KLU','PrecpMax10Time_KLU','PrecpMax60_KLU','PrecpMax60Time_KLU','SunShine_KLU','SunShineRate_KLU','GloblRad_KLU','VisbMean_KLU','EvapA_KLU','UVIMax_KLU','UVIMaxTime_KLU','CloudAmount_KLU','city_TPE','StnPres_TPE','SeaPres_TPE','StnPresMax_TPE','StnPresMaxTime_TPE','StnPresMin_TPE','StnPresMinTime_TPE','Temperature_TPE','TMax_TPE','TMaxTime_TPE','TMin_TPE','TMinTime_TPE','TdDewPoint_TPE','RH_TPE','RHMin_TPE','RHMinTime_TPE','WS_TPE','WD_TPE','WSGust_TPE','WDGust_TPE','WGustTime_TPE','Precp_TPE','PrecpHour_TPE','PrecpMax10_TPE','PrecpMax10Time_TPE','PrecpMax60_TPE','PrecpMax60Time_TPE','SunShine_TPE','SunShineRate_TPE','GloblRad_TPE','VisbMean_TPE','EvapA_TPE','UVIMax_TPE','UVIMaxTime_TPE','CloudAmount_TPE','city_TPH','StnPres_TPH','SeaPres_TPH','StnPresMax_TPH','StnPresMaxTime_TPH','StnPresMin_TPH','StnPresMinTime_TPH','Temperature_TPH','TMax_TPH','TMaxTime_TPH','TMin_TPH','TMinTime_TPH','TdDewPoint_TPH','RH_TPH','RHMin_TPH','RHMinTime_TPH','WS_TPH','WD_TPH','WSGust_TPH','WDGust_TPH','WGustTime_TPH','Precp_TPH','PrecpHour_TPH','PrecpMax10_TPH','PrecpMax10Time_TPH','PrecpMax60_TPH','PrecpMax60Time_TPH','SunShine_TPH','SunShineRate_TPH','GloblRad_TPH','VisbMean_TPH','EvapA_TPH','UVIMax_TPH','UVIMaxTime_TPH','CloudAmount_TPH','city_TYC','StnPres_TYC','SeaPres_TYC','StnPresMax_TYC','StnPresMaxTime_TYC','StnPresMin_TYC','StnPresMinTime_TYC','Temperature_TYC','TMax_TYC','TMaxTime_TYC','TMin_TYC','TMinTime_TYC','TdDewPoint_TYC','RH_TYC','RHMin_TYC','RHMinTime_TYC','WS_TYC','WD_TYC','WSGust_TYC','WDGust_TYC','WGustTime_TYC','Precp_TYC','PrecpHour_TYC','PrecpMax10_TYC','PrecpMax10Time_TYC','PrecpMax60_TYC','PrecpMax60Time_TYC','SunShine_TYC','SunShineRate_TYC','GloblRad_TYC','VisbMean_TYC','EvapA_TYC','UVIMax_TYC','UVIMaxTime_TYC','CloudAmount_TYC','city_HSC','StnPres_HSC','SeaPres_HSC','StnPresMax_HSC','StnPresMaxTime_HSC','StnPresMin_HSC','StnPresMinTime_HSC','Temperature_HSC','TMax_HSC','TMaxTime_HSC','TMin_HSC','TMinTime_HSC','TdDewPoint_HSC','RH_HSC','RHMin_HSC','RHMinTime_HSC','WS_HSC','WD_HSC','WSGust_HSC','WDGust_HSC','WGustTime_HSC','Precp_HSC','PrecpHour_HSC','PrecpMax10_HSC','PrecpMax10Time_HSC','PrecpMax60_HSC','PrecpMax60Time_HSC','SunShine_HSC','SunShineRate_HSC','GloblRad_HSC','VisbMean_HSC','EvapA_HSC','UVIMax_HSC','UVIMaxTime_HSC','CloudAmount_HSC','city_HSH','StnPres_HSH','SeaPres_HSH','StnPresMax_HSH','StnPresMaxTime_HSH','StnPresMin_HSH','StnPresMinTime_HSH','Temperature_HSH','TMax_HSH','TMaxTime_HSH','TMin_HSH','TMinTime_HSH','TdDewPoint_HSH','RH_HSH','RHMin_HSH','RHMinTime_HSH','WS_HSH','WD_HSH','WSGust_HSH','WDGust_HSH','WGustTime_HSH','Precp_HSH','PrecpHour_HSH','PrecpMax10_HSH','PrecpMax10Time_HSH','PrecpMax60_HSH','PrecpMax60Time_HSH','SunShine_HSH','SunShineRate_HSH','GloblRad_HSH','VisbMean_HSH','EvapA_HSH','UVIMax_HSH','UVIMaxTime_HSH','CloudAmount_HSH','city_MAL','StnPres_MAL','SeaPres_MAL','StnPresMax_MAL','StnPresMaxTime_MAL','StnPresMin_MAL','StnPresMinTime_MAL','Temperature_MAL','TMax_MAL','TMaxTime_MAL','TMin_MAL','TMinTime_MAL','TdDewPoint_MAL','RH_MAL','RHMin_MAL','RHMinTime_MAL','WS_MAL','WD_MAL','WSGust_MAL','WDGust_MAL','WGustTime_MAL','Precp_MAL','PrecpHour_MAL','PrecpMax10_MAL','PrecpMax10Time_MAL','PrecpMax60_MAL','PrecpMax60Time_MAL','SunShine_MAL','SunShineRate_MAL','GloblRad_MAL','VisbMean_MAL','EvapA_MAL','UVIMax_MAL','UVIMaxTime_MAL','CloudAmount_MAL','city_TXG','StnPres_TXG','SeaPres_TXG','StnPresMax_TXG','StnPresMaxTime_TXG','StnPresMin_TXG','StnPresMinTime_TXG','Temperature_TXG','TMax_TXG','TMaxTime_TXG','TMin_TXG','TMinTime_TXG','TdDewPoint_TXG','RH_TXG','RHMin_TXG','RHMinTime_TXG','WS_TXG','WD_TXG','WSGust_TXG','WDGust_TXG','WGustTime_TXG','Precp_TXG','PrecpHour_TXG','PrecpMax10_TXG','PrecpMax10Time_TXG','PrecpMax60_TXG','PrecpMax60Time_TXG','SunShine_TXG','SunShineRate_TXG','GloblRad_TXG','VisbMean_TXG','EvapA_TXG','UVIMax_TXG','UVIMaxTime_TXG','CloudAmount_TXG','city_CWH','StnPres_CWH','SeaPres_CWH','StnPresMax_CWH','StnPresMaxTime_CWH','StnPresMin_CWH','StnPresMinTime_CWH','Temperature_CWH','TMax_CWH','TMaxTime_CWH','TMin_CWH','TMinTime_CWH','TdDewPoint_CWH','RH_CWH','RHMin_CWH','RHMinTime_CWH','WS_CWH','WD_CWH','WSGust_CWH','WDGust_CWH','WGustTime_CWH','Precp_CWH','PrecpHour_CWH','PrecpMax10_CWH','PrecpMax10Time_CWH','PrecpMax60_CWH','PrecpMax60Time_CWH','SunShine_CWH','SunShineRate_CWH','GloblRad_CWH','VisbMean_CWH','EvapA_CWH','UVIMax_CWH','UVIMaxTime_CWH','CloudAmount_CWH','city_NTO','StnPres_NTO','SeaPres_NTO','StnPresMax_NTO','StnPresMaxTime_NTO','StnPresMin_NTO','StnPresMinTime_NTO','Temperature_NTO','TMax_NTO','TMaxTime_NTO','TMin_NTO','TMinTime_NTO','TdDewPoint_NTO','RH_NTO','RHMin_NTO','RHMinTime_NTO','WS_NTO','WD_NTO','WSGust_NTO','WDGust_NTO','WGustTime_NTO','Precp_NTO','PrecpHour_NTO','PrecpMax10_NTO','PrecpMax10Time_NTO','PrecpMax60_NTO','PrecpMax60Time_NTO','SunShine_NTO','SunShineRate_NTO','GloblRad_NTO','VisbMean_NTO','EvapA_NTO','UVIMax_NTO','UVIMaxTime_NTO','CloudAmount_NTO','city_YLH','StnPres_YLH','SeaPres_YLH','StnPresMax_YLH','StnPresMaxTime_YLH','StnPresMin_YLH','StnPresMinTime_YLH','Temperature_YLH','TMax_YLH','TMaxTime_YLH','TMin_YLH','TMinTime_YLH','TdDewPoint_YLH','RH_YLH','RHMin_YLH','RHMinTime_YLH','WS_YLH','WD_YLH','WSGust_YLH','WDGust_YLH','WGustTime_YLH','Precp_YLH','PrecpHour_YLH','PrecpMax10_YLH','PrecpMax10Time_YLH','PrecpMax60_YLH','PrecpMax60Time_YLH','SunShine_YLH','SunShineRate_YLH','GloblRad_YLH','VisbMean_YLH','EvapA_YLH','UVIMax_YLH','UVIMaxTime_YLH','CloudAmount_YLH','city_CYI','StnPres_CYI','SeaPres_CYI','StnPresMax_CYI','StnPresMaxTime_CYI','StnPresMin_CYI','StnPresMinTime_CYI','Temperature_CYI','TMax_CYI','TMaxTime_CYI','TMin_CYI','TMinTime_CYI','TdDewPoint_CYI','RH_CYI','RHMin_CYI','RHMinTime_CYI','WS_CYI','WD_CYI','WSGust_CYI','WDGust_CYI','WGustTime_CYI','Precp_CYI','PrecpHour_CYI','PrecpMax10_CYI','PrecpMax10Time_CYI','PrecpMax60_CYI','PrecpMax60Time_CYI','SunShine_CYI','SunShineRate_CYI','GloblRad_CYI','VisbMean_CYI','EvapA_CYI','UVIMax_CYI','UVIMaxTime_CYI','CloudAmount_CYI','city_CHY','StnPres_CHY','SeaPres_CHY','StnPresMax_CHY','StnPresMaxTime_CHY','StnPresMin_CHY','StnPresMinTime_CHY','Temperature_CHY','TMax_CHY','TMaxTime_CHY','TMin_CHY','TMinTime_CHY','TdDewPoint_CHY','RH_CHY','RHMin_CHY','RHMinTime_CHY','WS_CHY','WD_CHY','WSGust_CHY','WDGust_CHY','WGustTime_CHY','Precp_CHY','PrecpHour_CHY','PrecpMax10_CHY','PrecpMax10Time_CHY','PrecpMax60_CHY','PrecpMax60Time_CHY','SunShine_CHY','SunShineRate_CHY','GloblRad_CHY','VisbMean_CHY','EvapA_CHY','UVIMax_CHY','UVIMaxTime_CHY','CloudAmount_CHY','city_TNN','StnPres_TNN','SeaPres_TNN','StnPresMax_TNN','StnPresMaxTime_TNN','StnPresMin_TNN','StnPresMinTime_TNN','Temperature_TNN','TMax_TNN','TMaxTime_TNN','TMin_TNN','TMinTime_TNN','TdDewPoint_TNN','RH_TNN','RHMin_TNN','RHMinTime_TNN','WS_TNN','WD_TNN','WSGust_TNN','WDGust_TNN','WGustTime_TNN','Precp_TNN','PrecpHour_TNN','PrecpMax10_TNN','PrecpMax10Time_TNN','PrecpMax60_TNN','PrecpMax60Time_TNN','SunShine_TNN','SunShineRate_TNN','GloblRad_TNN','VisbMean_TNN','EvapA_TNN','UVIMax_TNN','UVIMaxTime_TNN','CloudAmount_TNN','city_KHH','StnPres_KHH','SeaPres_KHH','StnPresMax_KHH','StnPresMaxTime_KHH','StnPresMin_KHH','StnPresMinTime_KHH','Temperature_KHH','TMax_KHH','TMaxTime_KHH','TMin_KHH','TMinTime_KHH','TdDewPoint_KHH','RH_KHH','RHMin_KHH','RHMinTime_KHH','WS_KHH','WD_KHH','WSGust_KHH','WDGust_KHH','WGustTime_KHH','Precp_KHH','PrecpHour_KHH','PrecpMax10_KHH','PrecpMax10Time_KHH','PrecpMax60_KHH','PrecpMax60Time_KHH','SunShine_KHH','SunShineRate_KHH','GloblRad_KHH','VisbMean_KHH','EvapA_KHH','UVIMax_KHH','UVIMaxTime_KHH','CloudAmount_KHH','city_IUH','StnPres_IUH','SeaPres_IUH','StnPresMax_IUH','StnPresMaxTime_IUH','StnPresMin_IUH','StnPresMinTime_IUH','Temperature_IUH','TMax_IUH','TMaxTime_IUH','TMin_IUH','TMinTime_IUH','TdDewPoint_IUH','RH_IUH','RHMin_IUH','RHMinTime_IUH','WS_IUH','WD_IUH','WSGust_IUH','WDGust_IUH','WGustTime_IUH','Precp_IUH','PrecpHour_IUH','PrecpMax10_IUH','PrecpMax10Time_IUH','PrecpMax60_IUH','PrecpMax60Time_IUH','SunShine_IUH','SunShineRate_IUH','GloblRad_IUH','VisbMean_IUH','EvapA_IUH','UVIMax_IUH','UVIMaxTime_IUH','CloudAmount_IUH','city_ILN','StnPres_ILN','SeaPres_ILN','StnPresMax_ILN','StnPresMaxTime_ILN','StnPresMin_ILN','StnPresMinTime_ILN','Temperature_ILN','TMax_ILN','TMaxTime_ILN','TMin_ILN','TMinTime_ILN','TdDewPoint_ILN','RH_ILN','RHMin_ILN','RHMinTime_ILN','WS_ILN','WD_ILN','WSGust_ILN','WDGust_ILN','WGustTime_ILN','Precp_ILN','PrecpHour_ILN','PrecpMax10_ILN','PrecpMax10Time_ILN','PrecpMax60_ILN','PrecpMax60Time_ILN','SunShine_ILN','SunShineRate_ILN','GloblRad_ILN','VisbMean_ILN','EvapA_ILN','UVIMax_ILN','UVIMaxTime_ILN','CloudAmount_ILN','city_HWA','StnPres_HWA','SeaPres_HWA','StnPresMax_HWA','StnPresMaxTime_HWA','StnPresMin_HWA','StnPresMinTime_HWA','Temperature_HWA','TMax_HWA','TMaxTime_HWA','TMin_HWA','TMinTime_HWA','TdDewPoint_HWA','RH_HWA','RHMin_HWA','RHMinTime_HWA','WS_HWA','WD_HWA','WSGust_HWA','WDGust_HWA','WGustTime_HWA','Precp_HWA','PrecpHour_HWA','PrecpMax10_HWA','PrecpMax10Time_HWA','PrecpMax60_HWA','PrecpMax60Time_HWA','SunShine_HWA','SunShineRate_HWA','GloblRad_HWA','VisbMean_HWA','EvapA_HWA','UVIMax_HWA','UVIMaxTime_HWA','CloudAmount_HWA','city_TTT','StnPres_TTT','SeaPres_TTT','StnPresMax_TTT','StnPresMaxTime_TTT','StnPresMin_TTT','StnPresMinTime_TTT','Temperature_TTT','TMax_TTT','TMaxTime_TTT','TMin_TTT','TMinTime_TTT','TdDewPoint_TTT','RH_TTT','RHMin_TTT','RHMinTime_TTT','WS_TTT','WD_TTT','WSGust_TTT','WDGust_TTT','WGustTime_TTT','Precp_TTT','PrecpHour_TTT','PrecpMax10_TTT','PrecpMax10Time_TTT','PrecpMax60_TTT','PrecpMax60Time_TTT','SunShine_TTT','SunShineRate_TTT','GloblRad_TTT','VisbMean_TTT','EvapA_TTT','UVIMax_TTT','UVIMaxTime_TTT','CloudAmount_TTT','WarnMark']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5zqZtL2n9dC"
      },
      "source": [
        "清洗後之氣候資料輸出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltf8G7EcnAJo"
      },
      "source": [
        "import csv\n",
        "\n",
        "weather_list = weather_df.values.tolist()\n",
        "\n",
        "with open('weather_dataset.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  \n",
        "  writer.writerow(dataset_column_lists)\n",
        "\n",
        "  for wl in weather_list:\n",
        "    f = 0\n",
        "    for wm in warn_mark:\n",
        "      if wl[0] == wm:\n",
        "        wl[666] = 1 # w1[666]即為 warn_mark值之所在\n",
        "        writer.writerow(wl)\n",
        "        f = 1\n",
        "    if f == 0:\n",
        "      writer.writerow(wl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9IyKPYlYp02"
      },
      "source": [
        "# 環境與資料匯入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgRYSwx3YmYK",
        "outputId": "464b1839-c9a2-4df1-e121-6b591e7f1937"
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, GRU, TimeDistributed, RepeatVector, Lambda\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential, load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "weather = pd.read_csv('weather_dataset.csv', encoding='utf-8')\n",
        "market = pd.read_csv('price.csv', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (130,132,305,307) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8xJd6SzYvAY"
      },
      "source": [
        "# 資料預處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAjqMc-BbUey"
      },
      "source": [
        "# 市場\n",
        "1. 選定 台北一 市場\n",
        "2. 以空值前後二天之平均 補其 空值\n",
        "\n",
        "a. market_tp1_df['Avg_price'] 為整理後之台北一市場之平均價格 -- DataFrame \\\\\n",
        "b. market_other_tp1_df 為整理後之 台北一市場之其他資訊 -- DataFrame \\\\\n",
        "     Up_price, Mid_price, Low_price, Volume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZMH8_By0rh_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "01ccec3b-4234-469e-ee95-ed74ead1f06c"
      },
      "source": [
        "price_columns = ['Up_price', 'Mid_price', 'Low_price', 'Avg_price']\n",
        "columns = ['Up_price', 'Mid_price', 'Low_price', 'Avg_price', 'Volume']\n",
        "\n",
        "market_tp1_df = market.loc[market['Market'] == '台北一']\n",
        "market_tp1_df = market_tp1_df.rename(columns={'Date': 'date'}).set_index('date')\n",
        "market_tp1_df = market_tp1_df[columns]\n",
        "# med = price_tp1_df.loc[:,columns].median()\n",
        "# values = {'Up_price':med['Up_price'], 'Mid_price':med['Mid_price'], 'Low_price':med['Low_price'], 'Avg_price':med['Avg_price'], 'Volume':med['Volume']}\n",
        "# new_price_tp1_df = price_tp1_df.fillna(value=values)\n",
        "\n",
        "def fillna_fb_mean(self):\n",
        "    df_f = self.fillna(method='ffill')\n",
        "    df_b = self.fillna(method='bfill')\n",
        "    df_fb = (df_f+df_b)/2\n",
        "    return df_fb\n",
        "market_tp1_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Up_price</th>\n",
              "      <th>Mid_price</th>\n",
              "      <th>Low_price</th>\n",
              "      <th>Avg_price</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-02</th>\n",
              "      <td>30.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.5</td>\n",
              "      <td>15810.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>28.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>20.3</td>\n",
              "      <td>15126.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>28.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18693.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>28.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.3</td>\n",
              "      <td>22677.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-17</th>\n",
              "      <td>32.5</td>\n",
              "      <td>23.4</td>\n",
              "      <td>13.3</td>\n",
              "      <td>23.2</td>\n",
              "      <td>18276.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-18</th>\n",
              "      <td>30.9</td>\n",
              "      <td>20.4</td>\n",
              "      <td>12.1</td>\n",
              "      <td>20.9</td>\n",
              "      <td>14040.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-19</th>\n",
              "      <td>33.4</td>\n",
              "      <td>25.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>24.8</td>\n",
              "      <td>13485.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7840 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Up_price  Mid_price  Low_price  Avg_price   Volume\n",
              "date                                                          \n",
              "2000-01-02      30.0       22.0       14.0       20.2  22319.0\n",
              "2000-01-03      26.0       18.0       12.0       19.5  15810.0\n",
              "2000-01-04      28.0       18.0       12.0       20.3  15126.0\n",
              "2000-01-05      28.0       20.0       10.0       20.0  18693.0\n",
              "2000-01-06      28.0       20.0       10.0       20.3  22677.0\n",
              "...              ...        ...        ...        ...      ...\n",
              "2021-06-15       NaN        NaN        NaN        NaN      NaN\n",
              "2021-06-16       NaN        NaN        NaN        NaN      NaN\n",
              "2021-06-17      32.5       23.4       13.3       23.2  18276.0\n",
              "2021-06-18      30.9       20.4       12.1       20.9  14040.0\n",
              "2021-06-19      33.4       25.5       14.0       24.8  13485.0\n",
              "\n",
              "[7840 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5wW5lTZJcPl"
      },
      "source": [
        "# 價格\n",
        "# 以空值前後平均補空值\n",
        "# market_price_tp1_df = fillna_fb_mean(market_tp1_df.loc[:, price_columns])\n",
        "# market_avg_price_tp1_df = market_price_tp1_df['Avg_price']\n",
        "# market_avg_tp1_df = market_avg_tp1_df.reset_index()\n",
        "# market_other_price_tp1_df = market_price_tp1_df.drop(['Avg_price'], axis=1)\n",
        "market_tp1_df.loc[:, price_columns] = fillna_fb_mean(market_tp1_df.loc[:, price_columns])\n",
        "# market_tp1_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yub5M8xFJhSj"
      },
      "source": [
        "# 量\n",
        "# 以0補空值\n",
        "# market_volume_tp1_df\n",
        "# market_volume_tp1_df = market_tp1_df['Volume']\n",
        "# market_volume_tp1_df = market_volume_tp1_df.fillna(0)\n",
        "market_tp1_df['Volume'] = market_tp1_df['Volume'].fillna(0)\n",
        "\n",
        "# 非平均價之欄位\n",
        "# market_other_tp1_df = market_tp1_df.drop(['Avg_price'], axis=1)\n",
        "# market_other_tp1_df\n",
        "# market_tp1_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxk48tt7xMu"
      },
      "source": [
        "# 氣象\n",
        "1. 選出 與模型無關者排除\n",
        "2. 其餘暫無空值\n",
        "\n",
        "weather_df 為整理後之氣象資料 -- DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "392nswIYmedM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e3acaa-1a96-49f3-ab68-8caeb3b7a84e"
      },
      "source": [
        "# drop the useless \n",
        "drop_list = ['city_KLU','city_TPE','city_TPH','city_TYC','city_HSC','city_HSH','city_MAL','city_TXG','city_CWH','city_NTO','city_YLH','city_CYI','city_CHY','city_TNN','city_KHH','city_IUH','city_ILN','city_HWA','city_TTT','StnPresMaxTime_KLU','StnPresMinTime_KLU','TMaxTime_KLU','TMinTime_KLU','RHMinTime_KLU','WGustTime_KLU','PrecpMax10Time_KLU','PrecpMax60Time_KLU','UVIMaxTime_KLU','UVIMaxTime_KLU','StnPresMaxTime_TPE','StnPresMinTime_TPE','TMaxTime_TPE','TMinTime_TPE','RHMinTime_TPE','WGustTime_TPE','PrecpMax10Time_TPE','PrecpMax60_TPE','PrecpMax60Time_TPE','UVIMaxTime_TPE','StnPresMaxTime_TPH','StnPresMinTime_TPH','TMaxTime_TPH','TMinTime_TPH','RHMinTime_TPH','WGustTime_TPH','PrecpMax10Time_TPH','PrecpMax60_TPH','PrecpMax60Time_TPH','UVIMaxTime_TPH','StnPresMaxTime_TYC','StnPresMinTime_TYC','TMaxTime_TYC','TMinTime_TYC','RHMinTime_TYC','WGustTime_TYC','PrecpMax10Time_TYC','PrecpMax60_TYC','PrecpMax60Time_TYC','UVIMaxTime_TYC','StnPresMaxTime_HSC','StnPresMinTime_HSC','TMaxTime_HSC','TMinTime_HSC','RHMinTime_HSC','WGustTime_HSC','PrecpMax10Time_HSC','PrecpMax60_HSC','PrecpMax60Time_HSC','UVIMaxTime_HSC','StnPresMaxTime_HSH','StnPresMinTime_HSH','TMaxTime_HSH','TMinTime_HSH','RHMinTime_HSH','WGustTime_HSH','PrecpMax10Time_HSH','PrecpMax60_HSH','PrecpMax60Time_HSH','UVIMaxTime_HSH','StnPresMaxTime_MAL','StnPresMinTime_MAL','TMaxTime_MAL','TMinTime_MAL','RHMinTime_MAL','WGustTime_MAL','PrecpMax10Time_MAL','PrecpMax60_MAL','PrecpMax60Time_MAL','UVIMaxTime_MAL','StnPresMaxTime_TXG','StnPresMinTime_TXG','TMaxTime_TXG','TMinTime_TXG','RHMinTime_TXG','WGustTime_TXG','PrecpMax10Time_TXG','PrecpMax60_TXG','PrecpMax60Time_TXG','UVIMaxTime_TXG','StnPresMaxTime_CWH','StnPresMinTime_CWH','TMaxTime_CWH','TMinTime_CWH','RHMinTime_CWH','WGustTime_CWH','PrecpMax10Time_CWH','PrecpMax60_CWH','PrecpMax60Time_CWH','UVIMaxTime_CWH','StnPresMaxTime_NTO','StnPresMinTime_NTO','TMaxTime_NTO','TMinTime_NTO','RHMinTime_NTO','WGustTime_NTO','PrecpMax10Time_NTO','PrecpMax60_NTO','PrecpMax60Time_NTO','UVIMaxTime_NTO','StnPresMaxTime_YLH','StnPresMinTime_YLH','TMaxTime_YLH','TMinTime_YLH','RHMinTime_YLH','WGustTime_YLH','PrecpMax10Time_YLH','PrecpMax60_YLH','PrecpMax60Time_YLH','UVIMaxTime_YLH','StnPresMaxTime_CYI','StnPresMinTime_CYI','TMaxTime_CYI','TMinTime_CYI','RHMinTime_CYI','WGustTime_CYI','PrecpMax10Time_CYI','PrecpMax60_CYI','PrecpMax60Time_CYI','UVIMaxTime_CYI','StnPresMaxTime_CHY','StnPresMinTime_CHY','TMaxTime_CHY','TMinTime_CHY','RHMinTime_CHY','WGustTime_CHY','PrecpMax10Time_CHY','PrecpMax60_CHY','PrecpMax60Time_CHY','UVIMaxTime_CHY','StnPresMaxTime_TNN','StnPresMinTime_TNN','TMaxTime_TNN','TMinTime_TNN','RHMinTime_TNN','WGustTime_TNN','PrecpMax10Time_TNN','PrecpMax60_TNN','PrecpMax60Time_TNN','UVIMaxTime_TNN','StnPresMaxTime_KHH','StnPresMinTime_KHH','TMaxTime_KHH','TMinTime_KHH','RHMinTime_KHH','WGustTime_KHH','PrecpMax10Time_KHH','PrecpMax60_KHH','PrecpMax60Time_KHH','UVIMaxTime_KHH','StnPresMaxTime_IUH','StnPresMinTime_IUH','TMaxTime_IUH','TMinTime_IUH','RHMinTime_IUH','WGustTime_IUH','PrecpMax10Time_IUH','PrecpMax60_IUH','PrecpMax60Time_IUH','UVIMaxTime_IUH','StnPresMaxTime_ILN','StnPresMinTime_ILN','TMaxTime_ILN','TMinTime_ILN','RHMinTime_ILN','WGustTime_ILN','PrecpMax10Time_ILN','PrecpMax60_ILN','PrecpMax60Time_ILN','UVIMaxTime_ILN','StnPresMaxTime_HWA','StnPresMinTime_HWA','TMaxTime_HWA','TMinTime_HWA','RHMinTime_HWA','WGustTime_HWA','PrecpMax10Time_HWA','PrecpMax60_HWA','PrecpMax60Time_HWA','UVIMaxTime_HWA','StnPresMaxTime_TTT','StnPresMinTime_TTT','TMaxTime_TTT','TMinTime_TTT','RHMinTime_TTT','WGustTime_TTT','PrecpMax10Time_TTT','PrecpMax60_TTT','PrecpMax60Time_TTT','UVIMaxTime_TTT']\n",
        "print(len(drop_list))\n",
        "weather_df = weather.drop(drop_list, axis=1)\n",
        "weather_df = weather_df.set_index('date')\n",
        "# weather_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhwnpQmc5m22"
      },
      "source": [
        "Dataset 空值數量確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEch_sb6cZt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320341ef-cebc-4d09-c116-7a8cf9ddede8"
      },
      "source": [
        "# na 數量計算\n",
        "market_tp1_na_count = market_tp1_df.isna().sum()\n",
        "weather_na_count = weather_df.isna().sum()\n",
        "\n",
        "total_na_count = list() # 氣象空值查找\n",
        "for i in range(len(weather_na_count.index)):\n",
        "  if weather_na_count.values[i] != 0 :\n",
        "    total_na_count.append([weather_na_count.index[i], weather_na_count.values[i]])\n",
        "\n",
        "print(market_tp1_na_count)\n",
        "print(len(total_na_count))\n",
        "\n",
        "if not os.path.exists('market_tp1_df.xlsx'): market_tp1_df.to_excel('market_tp1_df.xlsx', index=True)\n",
        "if not os.path.exists('weather_df.csv'): weather_df.to_csv('weather_df.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Up_price     0\n",
            "Mid_price    0\n",
            "Low_price    0\n",
            "Avg_price    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdhJpyC1TA3d"
      },
      "source": [
        "# 資料範圍確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAK7JB22RlwT"
      },
      "source": [
        "資料區間確認\n",
        "1. 加入天氣\n",
        "2. 往前往後\n",
        "3. 期間\n",
        "4. 模型使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_pmCfbITFQq"
      },
      "source": [
        "# 是否要加入天氣資料\n",
        "add_weathen_data = True\n",
        "# # 是否要加入颱風資料\n",
        "# add_typhoon_data = True\n",
        "pastDay = 365\n",
        "futureDay = 3\n",
        "# 畫多少天的預測圖，要小於或等於上面的數字\n",
        "plotDay = 3\n",
        "# 訂定訓練資料的期間、測試資料的期間\n",
        "train_start_date = '2000-01-02'\n",
        "train_end_date = '2020-05-31'\n",
        "test_start_date = '2020-06-01'\n",
        "test_end_date = '2021-06-18'\n",
        "# 使用哪一個模型，目前有1, 2\n",
        "model_no = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-1rOEm5caxn"
      },
      "source": [
        "# 將資料整理為x, y\n",
        "def buildTrain(train, pastDay=30, futureDay=5):\n",
        "    x, y = [], []\n",
        "    for i in range(train.shape[0] - futureDay - pastDay):\n",
        "        x.append(train[i : i+pastDay])\n",
        "        y.append(train[i+pastDay+futureDay : i+pastDay+futureDay+1, -1])\n",
        "    return np.array(x), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgtiOJgKx2hS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWbmtqLZSPFv"
      },
      "source": [
        "df_all 合併之訓練資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM5-ARasTMg2"
      },
      "source": [
        "df_all = market_tp1_df\n",
        "# 是否要合併資料\n",
        "if add_weathen_data is True:\n",
        "    df_all = pd.merge(df_all, weather_df, how='inner', left_index = True, right_index = True)\n",
        "# if add_typhoon_data is True:\n",
        "#   df_all = pd.merge(df_all, df_typhoon, how='left', left_index = True, right_index = True).fillna(0)\n",
        "\n",
        "# 把平均價格移到最後1欄\n",
        "col_Avg_price = df_all.pop('Avg_price')\n",
        "df_all = pd.concat([df_all, col_Avg_price], 1)\n",
        "# df_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYt7pdlXTFkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9b401c-46aa-4dce-8bdf-12ecac16594e"
      },
      "source": [
        "# 將資料複製一份來作業, 將欄位index改為date\n",
        "df = df_all.copy()\n",
        "df = df.reset_index().rename(columns={'index': 'date'})\n",
        "\n",
        "# 依訓練資料的期間、測試資料的期間來切分資料\n",
        "df_train = df.iloc[df[(train_start_date <= df.date) & (df.date <= train_end_date)].index].set_index('date')\n",
        "df_test = df.iloc[df[(test_start_date <= df.date) & (df.date <= test_end_date)].index].set_index('date')\n",
        "\n",
        "# 將非數字的欄位移除\n",
        "df_train = df_train.select_dtypes(exclude=['object'])\n",
        "df_test = df_test.select_dtypes(exclude=['object'])\n",
        "\n",
        "print(df_train.dtypes)\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Up_price           float64\n",
            "Mid_price          float64\n",
            "Low_price          float64\n",
            "Volume             float64\n",
            "StnPres_KLU        float64\n",
            "                    ...   \n",
            "EvapA_TTT          float64\n",
            "UVIMax_TTT         float64\n",
            "CloudAmount_TTT    float64\n",
            "WarnMark             int64\n",
            "Avg_price          float64\n",
            "Length: 463, dtype: object\n",
            "(7456, 463)\n",
            "(383, 463)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aml05ZvV9cne"
      },
      "source": [
        "# 模型參數調整"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZPYArmwFbZc"
      },
      "source": [
        "x_sorted_data 為 氣候 MinMaxScaler後之資料 \\\\\n",
        "y_sorted_data 為 市場 MinMaxScaler後之資料\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUh4BimzJK-L"
      },
      "source": [
        "# # conversion to numpy array\n",
        "# # x, y = df_all.values, df_all['Avg_price'].values\n",
        "# df_train_scaled = df_all.values\n",
        "# # df_test_scaled = df_test.values\n",
        "\n",
        "# # scaling values for model\n",
        "# x_scale = MinMaxScaler()\n",
        "# y_scale = MinMaxScaler()\n",
        "\n",
        "# # 製作x_train, y_train\n",
        "# sorted_data = x_scale.fit_transform(df_train_scaled)\n",
        "# x_sorted_data, y_sorted_data = buildTrain(sorted_data, pastDay, futureDay)\n",
        "# y_sorted_data = y_scale.fit_transform(y_sorted_data.reshape(-1, x_sorted_data.shape[1]))\n",
        "\n",
        "# # # 製作x_test, y_test\n",
        "# # sorted_data = x_scale.fit_transform(df_train_scaled)\n",
        "# # x_sorted_data, y_sorted_data = buildTrain(sorted_data, pastDay, futureDay)\n",
        "# # y_sorted_data = y_scale.fit_transform(y_sorted_data.reshape(-1, x_sorted_data.shape[1]))\n",
        "\n",
        "# print(sorted_data.shape)\n",
        "# print(x_sorted_data.shape)\n",
        "# print(y_sorted_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VP9WE2A9Jyq"
      },
      "source": [
        "將原資料轉換為numpy\n",
        "並做出train test \n",
        "以 日期進行切割的方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdafWPO1cmWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d284815-389c-4312-ea03-c63c3ca06b3d"
      },
      "source": [
        "# conversion to numpy array\n",
        "# x, y = df_all.values, df_all['Avg_price'].values\n",
        "df_all_scaled = df_all.values\n",
        "# df_test_scaled = df_test.values\n",
        "\n",
        "# scaling values for model\n",
        "x_scale = MinMaxScaler()\n",
        "\n",
        "y_scale = MinMaxScaler()\n",
        "\n",
        "# 製作x與y的整體資料\n",
        "all_sorted_data = x_scale.fit_transform(df_all_scaled)\n",
        "x_sorted_data, y_sorted_data = buildTrain(all_sorted_data, pastDay, futureDay)\n",
        "\n",
        "\n",
        "y_sorted_data = y_scale.fit_transform(y_sorted_data.reshape(x_sorted_data.shape[0], -1))\n",
        "x_sorted_data.shape\n",
        "y_sorted_data.shape\n",
        "print(x_sorted_data.shape)\n",
        "print(all_sorted_data.shape)\n",
        "print(y_sorted_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7471, 365, 463)\n",
            "(7839, 463)\n",
            "(7471, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywOs0VI2g_7j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "e03982ec-8df1-4551-f677-f6fda51a581e"
      },
      "source": [
        "# # train test 依照期間切割\n",
        "x_train = x_sorted_data[ : df_train.shape[0]-pastDay-futureDay]\n",
        "x_test = x_sorted_data[df_train.shape[0]-pastDay-futureDay : ]\n",
        "y_train = y_sorted_data[ : df_train.shape[0]-pastDay-futureDay]\n",
        "y_test = y_sorted_data[df_train.shape[0]-pastDay-futureDay : ]\n",
        "\n",
        "\n",
        "# # 製作x_test, y_test\n",
        "# sorted_data = x_scale.fit_transform(df_train_scaled)\n",
        "# x_sorted_data, y_sorted_data = buildTrain(sorted_data, pastDay, futureDay)\n",
        "# y_sorted_data = y_scale.fit_transform(y_sorted_data.reshape(-1, x_sorted_data.shape[1]))\n",
        "\n",
        "print('all_sorted_data.shape:', all_sorted_data.shape)\n",
        "print('x_sorted_data.shape:', x_sorted_data.shape)\n",
        "print('y_sorted_data.shape:', y_sorted_data.shape)\n",
        "print('x_train.shape:', x_train.shape)\n",
        "print('x_test.shape:', x_test.shape)\n",
        "print('y_test.shape:', y_test.shape)\n",
        "\n",
        "# y_train = y_train[:,:,np.newaxis]\n",
        "# y_test = y_test[:,:,np.newaxis]\n",
        "print('y_train.shape:', y_train.shape)\n",
        "print('y_test.shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-35815a85482f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # train test 依照期間切割\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_sorted_data\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpastDay\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfutureDay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_sorted_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpastDay\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfutureDay\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_sorted_data\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpastDay\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfutureDay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_sorted_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpastDay\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfutureDay\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP3iey7cg38y"
      },
      "source": [
        "# # splitting train and test\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x_sorted_data, y_sorted_data, test_size=0.1)\n",
        "# x_train = x_train.reshape((-1,10,463))\n",
        "# y_train = y_train.reshape((-1,10))\n",
        "# x_test = x_test.reshape((-1,10,463))\n",
        "# y_test = y_test.reshape((-1,10))\n",
        "\n",
        "# print(\"x_train shape:\", x_train.shape)\n",
        "# print(\"y_train shape:\", y_train.shape)\n",
        "# print(\"x_test shape:\", x_test.shape)\n",
        "# print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# # pd.DataFrame(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xGVUasIZjjT"
      },
      "source": [
        "# 模型選擇"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SALiD48rntdc"
      },
      "source": [
        "# 模型1 (from 原本)\n",
        "def buildManyToManyModel(shape):\n",
        "    model = Sequential()\n",
        "    # model.add(GRU(units=256,\n",
        "    #     return_sequences=False,\n",
        "    #     input_shape=(shape[1], shape[2])))\n",
        "    \n",
        "    model.add(LSTM(units=256,\n",
        "        return_sequences=True,\n",
        "        input_shape=(shape[1], shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=128, return_sequences=False,))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baTga_umahTw"
      },
      "source": [
        "# 模型2\n",
        "def buildManyToManyModel2(shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(shape[1], shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(50, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(50, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvVsnT3kQA1u"
      },
      "source": [
        "# 模型訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPrrCMXtaJoy",
        "outputId": "46247916-be12-40f4-bce3-5f74240dfc2c"
      },
      "source": [
        "# 模型訓練\n",
        "if model_no == 1:\n",
        "    model = buildManyToManyModel(x_train.shape)\n",
        "    print('model1')\n",
        "    model_name = 'banana_prediction_model_v1'\n",
        "elif model_no == 2:\n",
        "    model = buildManyToManyModel2(x_train.shape)\n",
        "    print('model2')\n",
        "    model_name = 'banana_prediction_model_v2'\n",
        "# elif model_no == 3:\n",
        "#   model = buildManyToManyModel3(x_train.shape)\n",
        "#   print('model3')\n",
        "else:\n",
        "    print('選錯model了')\n",
        "\n",
        "callback = EarlyStopping(monitor=\"loss\", patience=30, verbose=1, mode=\"auto\")\n",
        "batch_size = 10\n",
        "epochs = 300\n",
        "validation_split = 0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 365, 256)          737280    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 365, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 934,529\n",
            "Trainable params: 934,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "model1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9NHw0Pu9hSj"
      },
      "source": [
        "# model = load_model(\"{}.h5\".format(model_name))\n",
        "# print(\"MODEL-LOADED\")\n",
        "\n",
        "# model.fit(x_train, y_train, epochs=500, batch_size=128, validation_data=(x_val, y_val), callbacks=[callback])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=[callback])\n",
        "model.save(\"{}.h5\".format(model_name))\n",
        "print('MODEL-SAVED')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvlf3x2A2tJK"
      },
      "source": [
        "fit()用於訓練具有給定輸入的模型。\n",
        "\n",
        "predict()用於實際預測。它爲輸入樣本生成輸出預測。\n",
        "\n",
        "evaluate()用於評估已經過訓練的模型。返回模型的損失值&指標值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vm1ifAdy8ZL"
      },
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print('Score: {}'.format(score))\n",
        "y_pre = model.predict(x_test)\n",
        "# yhat.shape\n",
        "# y_pre = y_scale.inverse_transform(y_pre.reshape(-1, 1))\n",
        "score\n",
        "y_pre.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiAkI9_x18cP"
      },
      "source": [
        "預測結果與實際結果的 數值迴轉 \\\n",
        "y_pre  --> pre_price \\\n",
        "y_test --> test_price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m55YI86mQKFr"
      },
      "source": [
        "# 結果展示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoPtCYX3M-27"
      },
      "source": [
        "# 原shape(383, 1) 目標shape(383, 463) \n",
        "np_zero = np.zeros((383,462))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4_XYJyG3nFn"
      },
      "source": [
        "def PriceInverse(predict, real):\n",
        "  pre_price_list = np.array([]).reshape(0, 383)\n",
        "  real_price_list = np.array([]).reshape(0, 383)\n",
        "  for i in range(1):\n",
        "    # pre_price\n",
        "    pre_price = x_scale.inverse_transform(np.insert(np_zero, 462, predict[:, 0], axis=1))\n",
        "    pre_price = pre_price[:, -1].reshape(1, -1)  \n",
        "    pre_price_list = np.append(pre_price_list, pre_price, axis=0)\n",
        "\n",
        "    test_price = x_scale.inverse_transform(np.insert(np_zero, 462, real[:, 0], axis=1))\n",
        "    test_price = test_price[:, -1].reshape(1, -1)\n",
        "    real_price_list = np.append(real_price_list, test_price, axis=0)\n",
        "\n",
        "  return pre_price_list, real_price_list\n",
        "  \n",
        "pre_price_list, real_price_list = PriceInverse(y_pre, y_test)\n",
        "pre_price_list.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7b4EOtxBntp"
      },
      "source": [
        "def DrawingPlot(predict, real):\n",
        "  plt.plot(predict[0][-100:], label='Predicted')\n",
        "  plt.plot(real[0][-100:], label='Ground Truth')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "DrawingPlot(pre_price_list, real_price_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Z8RzTPwO42"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "MSE = mean_squared_error(real_price_list.reshape(-1, 1), pre_price_list.reshape(-1, 1))\n",
        "RMSE = np.sqrt(MSE)\n",
        "R2 = r2_score(real_price_list.reshape(-1, 1), pre_price_list.reshape(-1, 1))\n",
        "print(f\"MSE value : {MSE}\", f\"\\nRMSE value : {RMSE}\", f\"\\nR2 score value : {R2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md9K67WAWOxi"
      },
      "source": [
        "儲存每一次試驗資訊"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmQmhlsVePFU"
      },
      "source": [
        "# 取得現在時間(TP)\n",
        "from datetime import datetime, timezone, timedelta\n",
        "# 設定為 +8 時區\n",
        "# 取得現在時間、指定時區、轉為 ISO 格式\n",
        "time_now = datetime.now(timezone(timedelta(hours=+8))).isoformat(timespec=\"seconds\")[5:16]\n",
        "time_now"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX6Du0YhWNyS"
      },
      "source": [
        "result_column_lists = ['Time', 'train_start_date', 'pastDay', 'futureDay', 'batch_size', 'epochs', 'validation_split','MSE', 'RMSE', 'R2']\n",
        "result_lists = [time_now, train_start_date, pastDay, futureDay, batch_size, epochs, validation_split, MSE, RMSE, R2]\n",
        "with open(f'result_{time_now}.csv', 'w', encoding='utf-8') as f_result:\n",
        "  result_writer = csv.writer(f_result)\n",
        "  result_writer.writerow(result_column_lists)\n",
        "  result_writer.writerow(result_lists)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvfQRk5xwQmd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJIdP0WcSPdp"
      },
      "source": [
        "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/ \\\\\n",
        "The input to every LSTM layer must be three-dimensional.\n",
        "\n",
        "The three dimensions of this input are:\n",
        "\n",
        "1. Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
        "2. Time Steps. One time step is one point of observation in the sample.\n",
        "3. Features. One feature is one observation at a time step."
      ]
    }
  ]
}